{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f735a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d16d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Cleaned-Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790e5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].replace({'China': 1, 'Italy': 2, 'Iran': 3, 'Republic of Korean':4, 'France':5,\n",
    "                     'Spain':6, 'Germany':7, 'UAE':8, 'Other-EUR':9, 'Other':10   }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43805a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.iloc[:,0:26]\n",
    "y = df.iloc[:,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc0ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa75584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature values (optional but often helpful)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd5e6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE architecture\n",
    "original_dim = X_train.shape[1]\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988f4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = keras.layers.Input(shape=(original_dim,))\n",
    "encoder_layer = keras.layers.Dense(128, activation='relu')(encoder_inputs)\n",
    "z_mean = keras.layers.Dense(latent_dim)(encoder_layer)\n",
    "z_log_var = keras.layers.Dense(latent_dim)(encoder_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8257c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = keras.layers.Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f087bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = keras.layers.Input(shape=(latent_dim,))\n",
    "decoder_layer = keras.layers.Dense(128, activation='relu')(decoder_inputs)\n",
    "outputs = keras.layers.Dense(original_dim, activation='sigmoid')(decoder_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d9d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the VAE model\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "vae_outputs = decoder(encoder(encoder_inputs)[2])\n",
    "vae = keras.Model(encoder_inputs, vae_outputs, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f009e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE loss\n",
    "reconstruction_loss = tf.keras.losses.mean_squared_error(encoder_inputs, vae_outputs)\n",
    "kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "vae_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "vae.add_loss(vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ea481c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6336/6336 [==============================] - 18s 2ms/step - loss: 1.0040 - val_loss: 1.0000\n",
      "Epoch 2/10\n",
      "6336/6336 [==============================] - 13s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 3/10\n",
      "6336/6336 [==============================] - 13s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 4/10\n",
      "6336/6336 [==============================] - 13s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 5/10\n",
      "6336/6336 [==============================] - 14s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 6/10\n",
      "6336/6336 [==============================] - 14s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 7/10\n",
      "6336/6336 [==============================] - 13s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 8/10\n",
      "6336/6336 [==============================] - 14s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 9/10\n",
      "6336/6336 [==============================] - 14s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 10/10\n",
      "6336/6336 [==============================] - 14s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ca7b2de20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# Train the VAE model\n",
    "vae.fit(X_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6aba2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7920/7920 [==============================] - 12s 1ms/step\n",
      "1980/1980 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "6336/6336 [==============================] - 23s 3ms/step - loss: -3437.7273 - accuracy: 0.0998 - val_loss: -9411.4805 - val_accuracy: 0.1008\n",
      "Epoch 2/10\n",
      "6336/6336 [==============================] - 14s 2ms/step - loss: -19481.8164 - accuracy: 0.0998 - val_loss: -31445.1797 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "6336/6336 [==============================] - 16s 2ms/step - loss: -47286.4180 - accuracy: 0.0998 - val_loss: -64887.1055 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "6336/6336 [==============================] - 16s 3ms/step - loss: -86369.9531 - accuracy: 0.0998 - val_loss: -109506.0469 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "6336/6336 [==============================] - 17s 3ms/step - loss: -136602.0000 - accuracy: 0.0998 - val_loss: -165165.2969 - val_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "6336/6336 [==============================] - 16s 3ms/step - loss: -197815.8125 - accuracy: 0.0998 - val_loss: -231842.4219 - val_accuracy: 0.1008\n",
      "Epoch 7/10\n",
      "6336/6336 [==============================] - 13s 2ms/step - loss: -270053.7812 - accuracy: 0.0998 - val_loss: -309452.8438 - val_accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "6336/6336 [==============================] - 12s 2ms/step - loss: -353246.2188 - accuracy: 0.0998 - val_loss: -397970.0312 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "6336/6336 [==============================] - 13s 2ms/step - loss: -447225.8438 - accuracy: 0.0998 - val_loss: -497285.9375 - val_accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "6336/6336 [==============================] - 12s 2ms/step - loss: -552167.3750 - accuracy: 0.0998 - val_loss: -607544.5000 - val_accuracy: 0.1008\n",
      "1980/1980 [==============================] - 3s 1ms/step - loss: -609098.2500 - accuracy: 0.1000\n",
      "Test accuracy: 0.10004734992980957\n"
     ]
    }
   ],
   "source": [
    "# Encode the data\n",
    "encoded_X_train, _, _ = encoder.predict(X_train)\n",
    "encoded_X_test, _, _ = encoder.predict(X_test)\n",
    "\n",
    "# Build a disease prediction model using the encoded features\n",
    "disease_model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(latent_dim,)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Use 'sigmoid' for binary classification\n",
    "])\n",
    "\n",
    "disease_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the disease prediction model\n",
    "disease_model.fit(encoded_X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = disease_model.evaluate(encoded_X_test, y_test)\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9860a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
